# This file is automatically @generated by Poetry 1.8.3 and should not be changed by hand.

[[package]]
name = "unsloth"
version = "2024.9.post4"
description = "2-5X faster LLM finetuning"
optional = false
python-versions = ">=3.9"
files = []
develop = false

[package.extras]
colab = ["unsloth[cu121]"]
colab-ampere = ["flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[colab-ampere-torch220]"]
colab-ampere-torch211 = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu121onlytorch211]", "unsloth[huggingface]"]
colab-ampere-torch220 = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu121onlytorch220]", "unsloth[huggingface]"]
colab-new = ["datasets (>=2.16.0)", "hf_transfer", "huggingface_hub", "numpy", "packaging", "protobuf (<4.0.0)", "psutil", "sentencepiece (>=0.2.0)", "tqdm", "transformers (>=4.44.2)", "tyro", "wheel (>=0.42.0)"]
colab-no-deps = ["accelerate (>=0.34.1)", "bitsandbytes (>=0.43.3)", "peft (>=0.7.1)", "protobuf (<4.0.0)", "trl (>=0.7.9,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1)", "xformers (<0.0.27)"]
colab-torch211 = ["bitsandbytes (>=0.43.3)", "unsloth[cu121onlytorch211]", "unsloth[huggingface]"]
colab-torch220 = ["bitsandbytes (>=0.43.3)", "unsloth[cu121onlytorch220]", "unsloth[huggingface]"]
conda = ["unsloth[huggingface]"]
cu118 = ["bitsandbytes (>=0.43.3)", "unsloth[cu118only]", "unsloth[huggingface]"]
cu118-ampere = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu118only]", "unsloth[huggingface]"]
cu118-ampere-torch211 = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu118onlytorch211]", "unsloth[huggingface]"]
cu118-ampere-torch220 = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu118onlytorch220]", "unsloth[huggingface]"]
cu118-ampere-torch230 = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu118onlytorch230]", "unsloth[huggingface]"]
cu118-ampere-torch240 = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu118onlytorch240]", "unsloth[huggingface]"]
cu118-torch211 = ["bitsandbytes (>=0.43.3)", "unsloth[cu118onlytorch211]", "unsloth[huggingface]"]
cu118-torch212 = ["bitsandbytes (>=0.43.3)", "unsloth[cu118onlytorch212]", "unsloth[huggingface]"]
cu118-torch220 = ["bitsandbytes (>=0.43.3)", "unsloth[cu118onlytorch220]", "unsloth[huggingface]"]
cu118-torch230 = ["bitsandbytes (>=0.43.3)", "unsloth[cu118onlytorch230]", "unsloth[huggingface]"]
cu118-torch240 = ["bitsandbytes (>=0.43.3)", "unsloth[cu118onlytorch240]", "unsloth[huggingface]"]
cu118only = ["xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.22.post7%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.22.post7%2Bcu118-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.22.post7%2Bcu118-cp39-cp39-manylinux2014_x86_64.whl"]
cu118onlytorch211 = ["xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.23%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.23%2Bcu118-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.23%2Bcu118-cp39-cp39-manylinux2014_x86_64.whl"]
cu118onlytorch212 = ["xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.23.post1%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.23.post1%2Bcu118-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.23.post1%2Bcu118-cp39-cp39-manylinux2014_x86_64.whl"]
cu118onlytorch220 = ["xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.24%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.24%2Bcu118-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.24%2Bcu118-cp39-cp39-manylinux2014_x86_64.whl"]
cu118onlytorch230 = ["xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.27%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.27%2Bcu118-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.27%2Bcu118-cp312-cp312-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.27%2Bcu118-cp39-cp39-manylinux2014_x86_64.whl"]
cu118onlytorch240 = ["xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.27.post2%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.27.post2%2Bcu118-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.27.post2%2Bcu118-cp312-cp312-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.27.post2%2Bcu118-cp39-cp39-manylinux2014_x86_64.whl"]
cu121 = ["bitsandbytes (>=0.43.3)", "unsloth[cu121only]", "unsloth[huggingface]"]
cu121-ampere = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu121only]", "unsloth[huggingface]"]
cu121-ampere-torch211 = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu121onlytorch211]", "unsloth[huggingface]"]
cu121-ampere-torch220 = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu121onlytorch220]", "unsloth[huggingface]"]
cu121-ampere-torch230 = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu121onlytorch230]", "unsloth[huggingface]"]
cu121-ampere-torch240 = ["bitsandbytes (>=0.43.3)", "flash-attn (>=2.6.3)", "ninja", "packaging", "unsloth[cu121onlytorch240]", "unsloth[huggingface]"]
cu121-torch211 = ["bitsandbytes (>=0.43.3)", "unsloth[cu121onlytorch211]", "unsloth[huggingface]"]
cu121-torch212 = ["bitsandbytes (>=0.43.3)", "unsloth[cu121onlytorch212]", "unsloth[huggingface]"]
cu121-torch220 = ["bitsandbytes (>=0.43.3)", "unsloth[cu121onlytorch220]", "unsloth[huggingface]"]
cu121-torch230 = ["bitsandbytes (>=0.43.3)", "unsloth[cu121onlytorch230]", "unsloth[huggingface]"]
cu121-torch240 = ["bitsandbytes (>=0.43.3)", "unsloth[cu121onlytorch240]", "unsloth[huggingface]"]
cu121only = ["xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp39-cp39-manylinux2014_x86_64.whl"]
cu121onlytorch211 = ["xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.23-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.23-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.23-cp39-cp39-manylinux2014_x86_64.whl"]
cu121onlytorch212 = ["xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.23.post1-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.23.post1-cp39-cp39-manylinux2014_x86_64.whl"]
cu121onlytorch220 = ["xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.24-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.24-cp39-cp39-manylinux2014_x86_64.whl"]
cu121onlytorch230 = ["xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.27-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.27-cp312-cp312-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.27-cp39-cp39-manylinux2014_x86_64.whl"]
cu121onlytorch240 = ["xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.27.post2-cp311-cp311-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.27.post2-cp312-cp312-manylinux2014_x86_64.whl", "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.27.post2-cp39-cp39-manylinux2014_x86_64.whl"]
huggingface = ["accelerate (>=0.34.1)", "datasets (>=2.16.0)", "hf_transfer", "huggingface_hub", "numpy", "packaging", "peft (>=0.7.1,!=0.11.0)", "protobuf (<4.0.0)", "psutil", "sentencepiece (>=0.2.0)", "tqdm", "transformers (>=4.44.2)", "trl (>=0.7.9,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1)", "tyro", "wheel (>=0.42.0)"]
kaggle = ["unsloth[huggingface]"]
kaggle-new = ["bitsandbytes (>=0.43.3)", "unsloth[huggingface]"]

[package.source]
type = "git"
url = "https://github.com/unslothai/unsloth.git"
reference = "HEAD"
resolved_reference = "79a2112ca4a775ce0b3cb75f5074136cb54ea6df"

[metadata]
lock-version = "2.0"
python-versions = "^3.12"
content-hash = "c664050521803daeb6400a617767ddaa4ee02bac90ab90e4c738f8a378089787"
